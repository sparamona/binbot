<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BinBot - Smart Inventory Management</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: #f1f5f9;
            color: #334155;
            line-height: 1.6;
            height: 100vh;
            overflow: hidden;
        }

        /* Main Layout - Two Column */
        .main-container {
            display: grid;
            grid-template-columns: 1fr 1fr;
            height: 100vh;
            gap: 1rem;
            padding: 1rem;
        }

        /* Left Side - Chat */
        .chat-section {
            background: white;
            border-radius: 1rem;
            box-shadow: 0 4px 6px rgba(0,0,0,0.05);
            display: flex;
            flex-direction: column;
            overflow: hidden;
        }

        .chat-header {
            background: #3b82f6;
            color: white;
            padding: 1rem;
            font-weight: 600;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }

        .header-title {
            font-size: 1rem;
        }

        .voice-controls {
            display: flex;
            align-items: center;
        }

        .voice-toggle {
            display: flex;
            align-items: center;
            cursor: pointer;
            font-size: 0.875rem;
            gap: 0.5rem;
        }

        .voice-toggle input[type="checkbox"] {
            display: none;
        }

        .toggle-slider {
            position: relative;
            width: 44px;
            height: 24px;
            background: rgba(255,255,255,0.3);
            border-radius: 12px;
            transition: background 0.3s;
        }

        .toggle-slider::before {
            content: '';
            position: absolute;
            top: 2px;
            left: 2px;
            width: 20px;
            height: 20px;
            background: white;
            border-radius: 50%;
            transition: transform 0.3s;
        }

        .voice-toggle input[type="checkbox"]:checked + .toggle-slider {
            background: rgba(255,255,255,0.5);
        }

        .voice-toggle input[type="checkbox"]:checked + .toggle-slider::before {
            transform: translateX(20px);
        }

        .toggle-label {
            color: rgba(255,255,255,0.9);
            font-weight: 500;
        }

        .voice-toggle input[type="checkbox"]:checked ~ .toggle-label {
            color: white;
        }

        #voice-btn.listening {
            background: #ef4444 !important;
            animation: pulse 1.5s infinite;
        }

        @keyframes pulse {
            0% { transform: scale(1); }
            50% { transform: scale(1.05); }
            100% { transform: scale(1); }
        }

        .chat-messages {
            flex: 1;
            padding: 1rem;
            overflow-y: auto;
            display: flex;
            flex-direction: column;
            gap: 0.75rem;
        }

        .message {
            padding: 0.75rem 1rem;
            border-radius: 1rem;
            max-width: 80%;
            word-wrap: break-word;
        }

        .message.user {
            background: #3b82f6;
            color: white;
            align-self: flex-end;
            border-bottom-right-radius: 0.25rem;
        }

        .message.assistant {
            background: #f1f5f9;
            color: #334155;
            align-self: flex-start;
            border-bottom-left-radius: 0.25rem;
        }

        .chat-input-area {
            padding: 1rem;
            border-top: 1px solid #e2e8f0;
            display: flex;
            gap: 0.5rem;
            align-items: center;
        }

        .chat-input {
            flex: 1;
            padding: 0.75rem;
            border: 1px solid #d1d5db;
            border-radius: 0.5rem;
            font-size: 0.875rem;
            outline: none;
        }

        .chat-input:focus {
            border-color: #3b82f6;
            box-shadow: 0 0 0 3px rgba(59, 130, 246, 0.1);
        }

        .btn {
            padding: 0.75rem 1rem;
            border: none;
            border-radius: 0.5rem;
            font-weight: 500;
            cursor: pointer;
            transition: all 0.2s;
            font-size: 0.875rem;
        }

        .btn-primary {
            background: #3b82f6;
            color: white;
        }

        .btn-primary:hover {
            background: #2563eb;
        }

        .btn-secondary {
            background: #6b7280;
            color: white;
        }

        .btn-secondary:hover {
            background: #4b5563;
        }

        /* Right Side - Current Bin */
        .bin-section {
            background: white;
            border-radius: 1rem;
            box-shadow: 0 4px 6px rgba(0,0,0,0.05);
            display: flex;
            flex-direction: column;
            overflow: hidden;
        }

        .bin-header {
            background: #10b981;
            color: white;
            padding: 1rem;
            font-weight: 600;
        }

        .bin-content {
            flex: 1;
            padding: 1rem;
            overflow-y: auto;
        }

        .bin-item {
            padding: 0.75rem;
            background: #f8fafc;
            border-radius: 0.5rem;
            border: 1px solid #e2e8f0;
            margin-bottom: 0.5rem;
        }

        .bin-item-name {
            font-weight: 500;
            margin-bottom: 0.25rem;
        }

        .bin-item-description {
            font-size: 0.875rem;
            color: #64748b;
        }

        .empty-state {
            text-align: center;
            color: #64748b;
            padding: 2rem;
        }

        /* Mobile Responsive */
        @media (max-width: 768px) {
            .main-container {
                grid-template-columns: 1fr;
                grid-template-rows: 1fr 1fr;
                gap: 0.5rem;
                padding: 0.5rem;
            }

            .chat-messages {
                padding: 0.75rem;
            }

            .chat-input-area {
                padding: 0.75rem;
            }

            .bin-content {
                padding: 0.75rem;
            }
        }
    </style>
</head>
<body>
    <div class="main-container">
        <!-- Left Side - Chat -->
        <div class="chat-section">
            <div class="chat-header">
                <div class="header-title">üí¨ Chat with BinBot</div>
                <div class="voice-controls">
                    <label class="voice-toggle">
                        <input type="checkbox" id="voice-mode-toggle">
                        <span class="toggle-slider"></span>
                        <span class="toggle-label">üé§ Voice Mode</span>
                    </label>
                </div>
            </div>
            <div class="chat-messages" id="chat-messages">
                <div class="message assistant">
                    Welcome! Try commands like "add screws to bin 5" or "search for arduino"
                </div>
            </div>
            <div class="chat-input-area">
                <input type="text" class="chat-input" id="chat-input" placeholder="Type a command..." onkeypress="if(event.key==='Enter') sendCommand()">
                <button class="btn btn-secondary" onclick="toggleVoiceInput()" id="voice-btn" title="Voice Input">üé§</button>
                <button class="btn btn-secondary" onclick="takePhoto()" title="Take Photo">üì∑</button>
                <button class="btn btn-primary" onclick="sendCommand()">Send</button>
            </div>
        </div>

        <!-- Right Side - Current Bin -->
        <div class="bin-section">
            <div class="bin-header" id="bin-header">
                üì¶ Current Bin: None Selected
            </div>
            <div class="bin-content" id="bin-content">
                <div class="empty-state">
                    No bin selected. Use a command like "show bin 3" to view bin contents.
                </div>
            </div>
        </div>
    </div>

    <script>
        // Global state
        let currentBin = null;
        let chatSessionId = null;
        let isVoiceModeEnabled = false;
        let isListening = false;
        let recognition = null;
        let speechSynthesis = window.speechSynthesis;
        let voiceProvider = 'browser'; // Will be loaded from config
        let voiceConfig = null;

        // Audio cache for faster repeated responses
        const audioCache = new Map();
        const MAX_CACHE_SIZE = 50;

        // API Configuration
        const API_BASE = window.location.origin;

        // Initialize app
        document.addEventListener('DOMContentLoaded', function() {
            // Generate session ID
            chatSessionId = 'session_' + Math.random().toString(36).substr(2, 9);

            // Initialize voice configuration and recognition
            initializeVoiceConfig();
            initializeVoiceRecognition();

            // Set up voice mode toggle
            const voiceModeToggle = document.getElementById('voice-mode-toggle');
            voiceModeToggle.addEventListener('change', function() {
                isVoiceModeEnabled = this.checked;
                console.log('Voice mode:', isVoiceModeEnabled ? 'enabled' : 'disabled');
            });
        });

        // API Helper Functions
        async function apiCall(endpoint, options = {}) {
            try {
                const url = endpoint.startsWith('/') ? `${API_BASE}${endpoint}` : endpoint;
                const response = await fetch(url, {
                    headers: {
                        'Content-Type': 'application/json',
                        ...options.headers
                    },
                    ...options
                });

                if (!response.ok) {
                    throw new Error(`HTTP ${response.status}: ${response.statusText}`);
                }

                return await response.json();
            } catch (error) {
                console.error('API call failed:', error);
                throw error;
            }
        }

        function addChatMessage(message, isUser) {
            const messagesContainer = document.getElementById('chat-messages');
            const messageDiv = document.createElement('div');
            messageDiv.className = `message ${isUser ? 'user' : 'assistant'}`;
            messageDiv.textContent = message;
            messagesContainer.appendChild(messageDiv);
            messagesContainer.scrollTop = messagesContainer.scrollHeight;
        }

        async function sendCommand() {
            const input = document.getElementById('chat-input');
            const command = input.value.trim();
            if (!command) return;

            // Add user message
            addChatMessage(command, true);
            input.value = '';

            try {
                const data = await apiCall('/nlp/command', {
                    method: 'POST',
                    body: JSON.stringify({
                        command: command,
                        session_id: chatSessionId
                    })
                });

                if (data.success) {
                    const response = data.data?.response || data.data?.message || 'Command processed successfully';
                    addChatMessage(response, false);

                    // Speak the response if voice mode is enabled
                    speakResponse(response);

                    // Update current bin from JSON response if provided
                    let currentBinFromResponse = null;

                    // Check for current_bin in the nested results structure
                    if (data.data?.results && data.data.results.length > 0) {
                        for (const result of data.data.results) {
                            if (result.result?.current_bin) {
                                currentBinFromResponse = result.result.current_bin;
                                break; // Use the first current_bin found
                            }
                        }
                    }

                    // Fallback: check for current_bin directly in data
                    if (!currentBinFromResponse && data.data?.current_bin) {
                        currentBinFromResponse = data.data.current_bin;
                    }

                    if (currentBinFromResponse) {
                        console.log(`Updating current bin to: ${currentBinFromResponse} (from JSON response)`);
                        await updateCurrentBin(currentBinFromResponse);
                    } else {
                        console.log('No current_bin found in response, keeping current bin unchanged');
                    }

                } else {
                    throw new Error(data.error?.message || 'Command failed');
                }
            } catch (error) {
                if (error.message.includes('Failed to fetch') || error.message.includes('NetworkError')) {
                    addChatMessage('‚ùå Backend server not running. Please start the server.', false);
                } else {
                    addChatMessage(`‚ùå Error: ${error.message}`, false);
                }
            }
        }



        async function takePhoto() {
            try {
                // Check if camera is supported
                if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
                    addChatMessage('‚ùå Camera not supported on this device', false);
                    return;
                }

                addChatMessage('üì∑ Opening camera...', false);

                // Get camera stream
                const stream = await navigator.mediaDevices.getUserMedia({
                    video: {
                        facingMode: 'environment', // Use back camera if available
                        width: { ideal: 1280 },
                        height: { ideal: 720 }
                    }
                });

                // Create camera modal
                showCameraModal(stream);

            } catch (error) {
                console.error('Camera error:', error);
                if (error.name === 'NotAllowedError') {
                    addChatMessage('‚ùå Camera permission denied. Please allow camera access and try again.', false);
                } else if (error.name === 'NotFoundError') {
                    addChatMessage('‚ùå No camera found on this device', false);
                } else {
                    addChatMessage(`‚ùå Camera error: ${error.message}`, false);
                }
            }
        }

        function showCameraModal(stream) {
            // Create camera modal
            const modal = document.createElement('div');
            modal.id = 'camera-modal';
            modal.style.cssText = `
                position: fixed;
                top: 0;
                left: 0;
                width: 100%;
                height: 100%;
                background: rgba(0,0,0,0.9);
                display: flex;
                flex-direction: column;
                align-items: center;
                justify-content: center;
                z-index: 2000;
            `;

            modal.innerHTML = `
                <div style="text-align: center; color: white; margin-bottom: 1rem;">
                    <h2>Take Photo for Inventory</h2>
                    <p>Position items in the frame and click capture</p>
                </div>
                <video id="camera-video" autoplay playsinline style="
                    max-width: 90vw;
                    max-height: 60vh;
                    border-radius: 0.5rem;
                    background: black;
                "></video>
                <canvas id="camera-canvas" style="display: none;"></canvas>
                <div style="margin-top: 1rem; display: flex; gap: 1rem;">
                    <button id="capture-btn" style="
                        padding: 1rem 2rem;
                        background: #3b82f6;
                        color: white;
                        border: none;
                        border-radius: 0.5rem;
                        font-size: 1rem;
                        cursor: pointer;
                    ">üì∑ Capture</button>
                    <button id="upload-btn" style="
                        padding: 1rem 2rem;
                        background: #10b981;
                        color: white;
                        border: none;
                        border-radius: 0.5rem;
                        font-size: 1rem;
                        cursor: pointer;
                    ">üìÅ Upload Photo</button>
                    <button id="cancel-camera-btn" style="
                        padding: 1rem 2rem;
                        background: #6b7280;
                        color: white;
                        border: none;
                        border-radius: 0.5rem;
                        font-size: 1rem;
                        cursor: pointer;
                    ">‚ùå Cancel</button>
                </div>
                <input type="file" id="photo-upload-input" accept="image/*" style="display: none;">
            `;

            document.body.appendChild(modal);

            // Set up video stream
            const video = document.getElementById('camera-video');
            video.srcObject = stream;

            // Handle capture
            document.getElementById('capture-btn').addEventListener('click', function() {
                capturePhoto(stream);
            });

            // Handle upload
            document.getElementById('upload-btn').addEventListener('click', function() {
                document.getElementById('photo-upload-input').click();
            });

            // Handle file selection
            document.getElementById('photo-upload-input').addEventListener('change', function(e) {
                if (e.target.files && e.target.files[0]) {
                    const file = e.target.files[0];
                    closeCameraModal(stream);
                    uploadSelectedPhoto(file);
                }
            });

            // Handle cancel
            document.getElementById('cancel-camera-btn').addEventListener('click', function() {
                closeCameraModal(stream);
            });

            // Close on escape key
            document.addEventListener('keydown', function(e) {
                if (e.key === 'Escape') {
                    closeCameraModal(stream);
                }
            });
        }

        async function capturePhoto(stream) {
            try {
                const video = document.getElementById('camera-video');
                const canvas = document.getElementById('camera-canvas');
                const ctx = canvas.getContext('2d');

                // Set canvas size to match video
                canvas.width = video.videoWidth;
                canvas.height = video.videoHeight;

                // Draw video frame to canvas
                ctx.drawImage(video, 0, 0);

                // Convert to blob
                canvas.toBlob(async function(blob) {
                    try {
                        // Close camera modal
                        closeCameraModal(stream);

                        // Show processing message
                        addChatMessage('üì∑ Photo captured! Analyzing image...', false);

                        // Upload and analyze image
                        await uploadAndAnalyzeImage(blob);

                    } catch (error) {
                        console.error('Error processing photo:', error);
                        addChatMessage(`‚ùå Error processing photo: ${error.message}`, false);
                    }
                }, 'image/jpeg', 0.8);

            } catch (error) {
                console.error('Error capturing photo:', error);
                addChatMessage(`‚ùå Error capturing photo: ${error.message}`, false);
            }
        }

        function closeCameraModal(stream) {
            // Stop camera stream
            if (stream) {
                stream.getTracks().forEach(track => track.stop());
            }

            // Remove modal
            const modal = document.getElementById('camera-modal');
            if (modal) {
                modal.remove();
            }
        }

        async function uploadAndAnalyzeImage(imageBlob) {
            try {
                // Use NLP endpoint for image analysis
                const formData = new FormData();
                formData.append('command', 'What items can you see in this image?');
                formData.append('session_id', chatSessionId);
                formData.append('image', imageBlob, 'camera-photo.jpg');

                const response = await fetch(`${API_BASE}/nlp/command-with-image`, {
                    method: 'POST',
                    body: formData
                });

                if (!response.ok) {
                    throw new Error(`HTTP ${response.status}: ${response.statusText}`);
                }

                const data = await response.json();

                if (data.success) {
                    const message = data.data?.response || data.data?.message || 'Image analyzed successfully';
                    addChatMessage(`‚úÖ ${message}`, false);

                    // Show identified items if available
                    const identifiedItems = data.data?.identified_items || [];
                    if (identifiedItems.length > 0) {
                        addChatMessage(`üîç I can see ${identifiedItems.length} item(s):`, false);
                        identifiedItems.forEach((item, index) => {
                            const confidence = item.confidence ? ` (${item.confidence}/10 confidence)` : '';
                            addChatMessage(`${index + 1}. ${item.name}${confidence}`, false);
                        });
                    }
                } else {
                    throw new Error(data.error?.message || 'Analysis failed');
                }

            } catch (error) {
                console.error('Upload error:', error);
                addChatMessage(`‚ùå Error uploading image: ${error.message}`, false);
            }
        }

        async function uploadSelectedPhoto(file) {
            try {
                // Show processing message
                addChatMessage('üìÅ Photo selected! Analyzing image...', false);

                // Upload and analyze the selected file
                await uploadAndAnalyzeImage(file);

            } catch (error) {
                console.error('Error processing selected photo:', error);
                addChatMessage(`‚ùå Error processing photo: ${error.message}`, false);
            }
        }

        async function updateCurrentBin(binId) {
            currentBin = binId;
            const binHeader = document.getElementById('bin-header');
            const binContent = document.getElementById('bin-content');

            binHeader.textContent = `üì¶ Current Bin: ${binId}`;
            binContent.innerHTML = '<div style="text-align: center; padding: 1rem;">Loading bin contents...</div>';

            try {
                // Use the new efficient bin-specific endpoint
                const data = await apiCall(`/test/bin/${binId}/items`);

                if (data.success) {
                    const binItems = data.data.items || [];

                    console.log(`Items in bin ${binId}:`, binItems);

                    if (binItems.length === 0) {
                        binContent.innerHTML = '<div class="empty-state">This bin is empty</div>';
                    } else {
                        binContent.innerHTML = binItems.map(item => `
                            <div class="bin-item">
                                <div class="bin-item-name">${item.name}</div>
                                <div class="bin-item-description">${item.description || 'No description'}</div>
                                <div style="font-size: 0.75rem; color: #64748b; margin-top: 0.25rem;">
                                    Item ID: ${item.id}
                                    ${item.images_count > 0 ? ` | üì∑ ${item.images_count} image(s)` : ''}
                                </div>
                            </div>
                        `).join('');
                    }
                } else {
                    throw new Error(data.error?.message || 'Failed to retrieve bin items');
                }
            } catch (error) {
                console.error('Error loading bin contents:', error);
                binContent.innerHTML = `<div class="empty-state">Failed to load bin contents: ${error.message}</div>`;
            }
        }

        // Voice Recognition Functions
        function initializeVoiceRecognition() {
            if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
                const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
                recognition = new SpeechRecognition();

                recognition.continuous = false;
                recognition.interimResults = false;
                recognition.lang = 'en-US';

                recognition.onstart = function() {
                    isListening = true;
                    const voiceBtn = document.getElementById('voice-btn');
                    voiceBtn.classList.add('listening');
                    voiceBtn.innerHTML = 'üî¥';
                    console.log('Voice recognition started');
                };

                recognition.onresult = function(event) {
                    const transcript = event.results[0][0].transcript;
                    console.log('Voice input:', transcript);

                    // Put the transcript in the input field
                    const chatInput = document.getElementById('chat-input');
                    chatInput.value = transcript;

                    // Automatically send the command
                    sendCommand();
                };

                recognition.onerror = function(event) {
                    console.error('Voice recognition error:', event.error);
                    stopListening();

                    if (event.error === 'not-allowed') {
                        addChatMessage('‚ùå Microphone permission denied. Please allow microphone access.', false);
                    } else if (event.error === 'no-speech') {
                        addChatMessage('üé§ No speech detected. Try again.', false);
                    } else {
                        addChatMessage(`‚ùå Voice recognition error: ${event.error}`, false);
                    }
                };

                recognition.onend = function() {
                    stopListening();
                };

            } else {
                console.log('Speech recognition not supported');
            }
        }

        function toggleVoiceInput() {
            if (!recognition) {
                addChatMessage('‚ùå Voice recognition not supported on this browser', false);
                return;
            }

            if (isListening) {
                stopListening();
            } else {
                startListening();
            }
        }

        function startListening() {
            if (recognition && !isListening) {
                try {
                    recognition.start();
                    addChatMessage('üé§ Listening... Speak your command', false);
                } catch (error) {
                    console.error('Error starting voice recognition:', error);
                    addChatMessage('‚ùå Could not start voice recognition', false);
                }
            }
        }

        function stopListening() {
            isListening = false;
            const voiceBtn = document.getElementById('voice-btn');
            voiceBtn.classList.remove('listening');
            voiceBtn.innerHTML = 'üé§';

            if (recognition) {
                recognition.stop();
            }
        }

        // Initialize Voice Configuration
        async function initializeVoiceConfig() {
            try {
                const response = await fetch(`${API_BASE}/voice/config`);
                const data = await response.json();

                if (data.provider) {
                    voiceProvider = data.provider;
                    voiceConfig = data;
                    console.log(`Voice provider: ${voiceProvider}`, data.current_settings);
                } else {
                    voiceProvider = 'browser'; // fallback
                }
            } catch (error) {
                console.error('Failed to load voice config:', error);
                voiceProvider = 'browser'; // fallback
            }
        }

        // Speak Response (Text-to-Speech)
        async function speakResponse(text) {
            if (!isVoiceModeEnabled) return;
            if (!text || text.trim().length === 0) return;

            // Clean up the text for speech
            const cleanText = text
                .replace(/[üì¶üîß‚úÖ‚ùåüí°üì∑üé§üî¥]/g, '') // Remove emojis
                .replace(/\*\*/g, '') // Remove markdown bold
                .replace(/`[^`]*`/g, '') // Remove code blocks
                .replace(/\n+/g, '. ') // Replace newlines with periods
                .trim();

            if (!cleanText) return;

            try {
                if (voiceProvider === 'openai') {
                    await speakWithOpenAI(cleanText);
                } else {
                    await speakWithBrowser(cleanText);
                }
            } catch (error) {
                console.error('Error in speech synthesis:', error);
                // Fallback to browser TTS
                if (voiceProvider === 'openai') {
                    await speakWithBrowser(cleanText);
                }
            }
        }

        // OpenAI TTS Implementation with caching
        async function speakWithOpenAI(text) {
            try {
                // Check cache first for faster repeated responses
                const cacheKey = text.toLowerCase().trim();
                if (audioCache.has(cacheKey)) {
                    console.log('Using cached audio for:', text);
                    const cachedAudio = audioCache.get(cacheKey);
                    cachedAudio.currentTime = 0; // Reset to beginning
                    await cachedAudio.play();
                    return;
                }

                const response = await fetch(`${API_BASE}/voice/tts`, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({
                        text: text
                    })
                });

                const result = await response.json();

                if (result.success && result.audio_data) {
                    // Convert base64 to audio blob
                    const audioData = atob(result.audio_data);
                    const audioArray = new Uint8Array(audioData.length);
                    for (let i = 0; i < audioData.length; i++) {
                        audioArray[i] = audioData.charCodeAt(i);
                    }

                    const audioBlob = new Blob([audioArray], {
                        type: result.audio_format === 'opus' ? 'audio/ogg' : 'audio/mpeg'
                    });
                    const audioUrl = URL.createObjectURL(audioBlob);
                    const audio = new Audio(audioUrl);

                    // Cache the audio for faster repeated responses
                    if (audioCache.size >= MAX_CACHE_SIZE) {
                        // Remove oldest entry
                        const firstKey = audioCache.keys().next().value;
                        const oldAudio = audioCache.get(firstKey);
                        URL.revokeObjectURL(oldAudio.src);
                        audioCache.delete(firstKey);
                    }
                    audioCache.set(cacheKey, audio);

                    await audio.play();
                    console.log(`OpenAI TTS played: ${result.voice} voice, ${result.model} model`);
                } else {
                    throw new Error(result.message || 'OpenAI TTS failed');
                }
            } catch (error) {
                console.error('OpenAI TTS error:', error);
                throw error;
            }
        }

        // Browser TTS Implementation
        async function speakWithBrowser(text) {
            return new Promise((resolve, reject) => {
                if (!speechSynthesis) {
                    reject(new Error('Browser TTS not supported'));
                    return;
                }

                // Cancel any ongoing speech
                speechSynthesis.cancel();

                const utterance = new SpeechSynthesisUtterance(text);

                // Use config settings if available
                if (voiceConfig && voiceConfig.current_settings) {
                    const settings = voiceConfig.current_settings;
                    utterance.rate = settings.tts_rate || 0.9;
                    utterance.pitch = settings.tts_pitch || 1.0;
                    utterance.volume = settings.tts_volume || 0.8;
                } else {
                    utterance.rate = 0.9;
                    utterance.pitch = 1.0;
                    utterance.volume = 0.8;
                }

                utterance.onend = () => resolve();
                utterance.onerror = (error) => reject(error);

                speechSynthesis.speak(utterance);
                console.log('Browser TTS played');
            });
        }
    </script>
</body>
</html>
